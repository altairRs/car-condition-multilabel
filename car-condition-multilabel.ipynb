{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_iB_0yJpp7G"
      },
      "source": [
        "# Классификация повреждений автомобиля — мульти‑лейбл\n",
        "\n",
        "## Описание задачи и подход\n",
        "\n",
        "- Проблема: чистые автомобили часто классифицировались как scratch из‑за недостатка чистых примеров в обучении.\n",
        "- Решение: мульти‑лейбл бинарная классификация; категория датасета \"car\" интерпретируется как метка \"clean\" для обогащения класса clean.\n",
        "- Метки: scratch, dent, rust, dirt, clean.\n",
        "- Основная идея: больше чистых примеров → меньше ложных срабатываний на scratch.\n",
        "- Логи: управление подробностью вывода через переменную `VERBOSE` (по умолчанию False).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phb05Tg3pp7I"
      },
      "source": [
        "## 1. Установка библиотек\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpfQL6eGpp7J",
        "outputId": "c9eb99c3-f345-41de-d572-400770abe6fd"
      },
      "outputs": [],
      "source": [
        "# Установка всех необходимых библиотек\n",
        "!pip -q install roboflow timm albumentations torch torchvision scikit-learn matplotlib tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Verbosity controls\n",
        "VERBOSE = False\n",
        "\n",
        "def vprint(*args, **kwargs):\n",
        "    if VERBOSE:\n",
        "        print(*args, **kwargs)\n",
        "\n",
        "vprint(f\"Используется устройство: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McTnJVBApp7J"
      },
      "source": [
        "## 2. Загрузка датасетов (строго 2 набора)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxmls0xMpp7K",
        "outputId": "c2103e22-308c-48b9-d7fa-e3dc0b1923a1"
      },
      "outputs": [],
      "source": [
        "# Загрузка строго двух датасетов\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "\n",
        "api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"ROBOFLOW_API_KEY не установлен. В Colab выполните: %env ROBOFLOW_API_KEY=your_key\")\n",
        "\n",
        "rf = Roboflow(api_key=api_key)\n",
        "\n",
        "vprint(\"Скачивание датасета 1: грязные/чистые машины...\")\n",
        "project = rf.workspace(\"anuar\").project(\"dirt-car-450x3-xim8d\")\n",
        "version = project.version(1)\n",
        "if VERBOSE:\n",
        "    dataset1 = version.download(\"coco\")\n",
        "else:\n",
        "    import contextlib, io, sys\n",
        "    with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
        "        dataset1 = version.download(\"coco\")\n",
        "\n",
        "vprint(\"Скачивание датасета 2: типы повреждений...\")\n",
        "project = rf.workspace(\"anuar\").project(\"rust-and-scrach-t94pa\")\n",
        "version = project.version(1)\n",
        "if VERBOSE:\n",
        "    dataset2 = version.download(\"coco\")\n",
        "else:\n",
        "    import contextlib, io, sys\n",
        "    with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
        "        dataset2 = version.download(\"coco\")\n",
        "\n",
        "vprint(\"Оба датасета загружены.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFcCPT3vpp7K"
      },
      "source": [
        "## 3. Создание бинарных меток для мульти‑лейбл\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz4JLk__pp7K",
        "outputId": "da285010-4de8-46fe-b327-175e53384523"
      },
      "outputs": [],
      "source": [
        "# 5 бинарных классов (каждый может быть 0 или 1)\n",
        "BINARY_CLASSES = ['scratch', 'dent', 'rust', 'dirt', 'clean']\n",
        "print(f\"Бинарные классы: {BINARY_CLASSES}\")\n",
        "\n",
        "# Счётчик для отладки (показать только первые несколько примеров)\n",
        "debug_counter = 0\n",
        "\n",
        "def create_binary_labels(annotations, dataset_type):\n",
        "    \"\"\"\n",
        "    Создание бинарных меток для multi-label классификации\n",
        "    ТОЧНЫЕ названия классов по информации пользователя:\n",
        "    - Датасет 1 (DIRT CAR): dirty, clean\n",
        "    - Датасет 2 (RUST AND SCRATCH): car, dunt, rust, scratch\n",
        "    \"\"\"\n",
        "    global debug_counter\n",
        "    labels = {cls: 0 for cls in BINARY_CLASSES}\n",
        "    show_debug = debug_counter < 10  # Показать отладку только для первых 10 изображений\n",
        "\n",
        "    if dataset_type == 'dirt':\n",
        "        # Датасет 1: DIRT-CAR с классами dirty, clean\n",
        "        for ann in annotations:\n",
        "            category = ann['category_name'].lower()\n",
        "            if show_debug:\n",
        "                print(f\"    Dirt dataset - найден класс: '{ann['category_name']}'\")\n",
        "            if category == 'clean':\n",
        "                labels['clean'] = 1\n",
        "            elif category == 'dirty':\n",
        "                labels['dirt'] = 1\n",
        "\n",
        "    elif dataset_type == 'damage':\n",
        "        # Датасет 2: RUST-AND-SCRATCH с классами car, dunt, rust, scratch\n",
        "        has_damage = False\n",
        "        has_car_category = False\n",
        "\n",
        "        for ann in annotations:\n",
        "            category = ann['category_name'].lower()\n",
        "            if show_debug:\n",
        "                print(f\"    Damage dataset - найден класс: '{ann['category_name']}'\")\n",
        "            if category == 'scratch' or category == 'scracth':  # Исправляем опечатку в данных\n",
        "                labels['scratch'] = 1\n",
        "                has_damage = True\n",
        "            elif category == 'dunt':  # Точное название!\n",
        "                labels['dent'] = 1\n",
        "                has_damage = True\n",
        "            elif category == 'rust':\n",
        "                labels['rust'] = 1\n",
        "                has_damage = True\n",
        "            elif category == 'car':\n",
        "                has_car_category = True\n",
        "\n",
        "        # КЛЮЧЕВАЯ ЛОГИКА ТИММЕЙТА: car без повреждений = clean\n",
        "        if has_car_category and not has_damage:\n",
        "            labels['clean'] = 1\n",
        "            if show_debug:\n",
        "                print(f\"    Найдена категория 'car' без повреждений → clean=1\")\n",
        "\n",
        "    if show_debug:\n",
        "        print(f\"    Итоговые метки: {dict(zip(BINARY_CLASSES, labels.values()))}\")\n",
        "\n",
        "    debug_counter += 1\n",
        "    return list(labels.values())  # [scratch, dent, rust, dirt, clean]\n",
        "\n",
        "print(\"Функция создания бинарных меток готова\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ4EUmQEpp7L"
      },
      "source": [
        "## 4. Обработка данных и формирование единого датасета\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPJ5jptgpp7L",
        "outputId": "9ff0923a-8682-440f-a651-07c5656151ae"
      },
      "outputs": [],
      "source": [
        "def process_dataset(dataset_dir, dataset_type):\n",
        "    \"\"\"Обработка датасета и создание бинарных меток\"\"\"\n",
        "    data = []\n",
        "    vprint(f\"Обрабатываем папку: {dataset_dir} (тип: {dataset_type})\")\n",
        "\n",
        "    for split in ['train', 'valid', 'test', 'val']:\n",
        "        split_path = Path(dataset_dir) / split\n",
        "        vprint(f\"   Проверяем папку: {split_path}\")\n",
        "\n",
        "        if not split_path.exists():\n",
        "            vprint(f\"   Папка {split} не найдена\")\n",
        "            continue\n",
        "\n",
        "        ann_file = split_path / '_annotations.coco.json'\n",
        "        vprint(f\"   Ищем файл аннотаций: {ann_file}\")\n",
        "\n",
        "        if not ann_file.exists():\n",
        "            vprint(f\"   Файл аннотаций не найден: {ann_file}\")\n",
        "            continue\n",
        "\n",
        "        vprint(f\"   Загружаем аннотации из: {ann_file}\")\n",
        "        with open(ann_file) as f:\n",
        "            coco_data = json.load(f)\n",
        "\n",
        "        categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "        vprint(f\"   Найденные классы: {list(categories.values())}\")\n",
        "\n",
        "        img_anns = defaultdict(list)\n",
        "        for ann in coco_data['annotations']:\n",
        "            ann['category_name'] = categories[ann['category_id']]\n",
        "            img_anns[ann['image_id']].append(ann)\n",
        "\n",
        "        images_processed = 0\n",
        "        for img in coco_data['images']:\n",
        "            img_path = split_path / img['file_name']\n",
        "            if img_path.exists():\n",
        "                binary_labels = create_binary_labels(img_anns[img['id']], dataset_type)\n",
        "\n",
        "                data.append({\n",
        "                    'image_path': str(img_path),\n",
        "                    'binary_labels': binary_labels,  # [scratch, dent, rust, dirt, clean]\n",
        "                    'split': split,\n",
        "                    'dataset_type': dataset_type\n",
        "                })\n",
        "                images_processed += 1\n",
        "\n",
        "        vprint(f\"   Обработано изображений в {split}: {images_processed}\")\n",
        "\n",
        "    vprint(f\"Итого обработано из {dataset_dir}: {len(data)} изображений\")\n",
        "    return data\n",
        "\n",
        "# Обработка обоих датасетов\n",
        "all_data = []\n",
        "\n",
        "vprint(\"Поиск датасетов...\")\n",
        "vprint(\"Найденные папки:\", [d for d in os.listdir('.') if os.path.isdir(d)])\n",
        "\n",
        "# Датасет 1: DIRT-CAR (dirty, clean)\n",
        "dirt_dataset_found = False\n",
        "for d in os.listdir('.'):\n",
        "    if ('DIRT-CAR' in d.upper() or 'dirt-car' in d.lower()) and os.path.isdir(d):\n",
        "        vprint(f\"Найден датасет грязи: {d}\")\n",
        "        data = process_dataset(d, 'dirt')\n",
        "        all_data.extend(data)\n",
        "        dirt_dataset_found = True\n",
        "        break\n",
        "\n",
        "if not dirt_dataset_found:\n",
        "    vprint(\"Датасет DIRT-CAR не найден\")\n",
        "\n",
        "# Датасет 2: RUST-AND-SCRATCH (car, dunt, rust, scratch)\n",
        "damage_dataset_found = False\n",
        "for d in os.listdir('.'):\n",
        "    if ('RUST' in d.upper() and 'SCRACH' in d.upper()) or ('rust' in d.lower() and 'scrach' in d.lower()):\n",
        "        if os.path.isdir(d):\n",
        "            vprint(f\"Найден датасет повреждений: {d}\")\n",
        "            data = process_dataset(d, 'damage')\n",
        "            all_data.extend(data)\n",
        "            damage_dataset_found = True\n",
        "            break\n",
        "\n",
        "if not damage_dataset_found:\n",
        "    vprint(\"Датасет RUST-AND-SCRATCH не найден\")\n",
        "\n",
        "vprint(f\"Всего изображений: {len(all_data)}\")\n",
        "\n",
        "# Показать распределение классов\n",
        "if all_data:\n",
        "    labels_array = np.array([item['binary_labels'] for item in all_data])\n",
        "    print(\"\\\\nРаспределение классов:\")\n",
        "    for i, class_name in enumerate(BINARY_CLASSES):\n",
        "        count = labels_array[:, i].sum()\n",
        "        print(f\"{class_name}: {count} изображений ({count/len(all_data)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nДанные обработаны. Ключ: больше чистых примеров из категории 'car'\")\n",
        "else:\n",
        "    print(\"Ошибка: данные не загружены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHp_r0Hnpp7M"
      },
      "source": [
        "## 5. Модель и обучение (весь код)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63a18b990ecd492b8103ef510a42f0cc",
            "447ba533d0ea4df1b4172773b318297b",
            "f38be968b2f947d094e1d30b19797f46",
            "d960fcbd3e334d9dad2ff80e60834645",
            "7bb399cb03cb45ad83cc5a441039eb45",
            "dfadec0698b741ca9c79ca041c6dea4a",
            "5e58631bd178407f981b41d03219d732",
            "938cb74eebdb4793905cb5313b81d3a7",
            "00c8488c25d848b3bb293633293d0460",
            "3e84c4581b64438b8230db7ada722d73",
            "0e10b07105194f6c8e4c664a0f6f5746"
          ]
        },
        "id": "ChQBAQEWpp7M",
        "outputId": "c2bc5160-feaa-415d-db97-0c2e120c82f9"
      },
      "outputs": [],
      "source": [
        "# ЭКСТРЕМАЛЬНО ЛЕГКАЯ РЕАЛИЗАЦИЯ ДЛЯ COLAB\n",
        "\n",
        "# ===== ВСЕ НЕОБХОДИМЫЕ ИМПОРТЫ (на случай запуска не по порядку) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm as _tqdm\n",
        "\n",
        "def tqdm(iterable=None, **kwargs):\n",
        "    if VERBOSE:\n",
        "        return _tqdm(iterable=iterable, **kwargs)\n",
        "    # silent passthrough\n",
        "    return iterable\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Устройство и проверка данных\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "vprint(f\"Устройство: {device}\")\n",
        "\n",
        "# Проверяем, загружены ли данные из предыдущих ячеек\n",
        "if 'all_data' not in globals() or not all_data:\n",
        "    print(\"Данные не загружены\")\n",
        "    print(\"   Запустите ячейки по порядку: 1 → 2 → 3 → 4 → 5\")\n",
        "    print(\"   Убедитесь, что ячейка 4 (Обработка данных) выполнена успешно\")\n",
        "else:\n",
        "    print(f\"Данные загружены: {len(all_data)} изображений\")\n",
        "\n",
        "# Классы (если не определены)\n",
        "if 'BINARY_CLASSES' not in globals():\n",
        "    BINARY_CLASSES = ['scratch', 'dent', 'rust', 'dirt', 'clean']\n",
        "    print(f\"Классы определены: {BINARY_CLASSES}\")\n",
        "\n",
        "# Multi-Label модель\n",
        "class MultiLabelCarClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        # Самый маленький backbone из timm\n",
        "        self.backbone = timm.create_model('tf_efficientnetv2_s.in1k', pretrained=True, num_classes=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)\n",
        "            feat_dim = self.backbone(dummy).shape[1]\n",
        "\n",
        "        # Полноценный классификатор с dropout\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(feat_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        print(f\"Модель: {feat_dim} → {num_classes} (EfficientNetV2-S)\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.backbone(x))\n",
        "\n",
        "# Датасет\n",
        "class MultiLabelCarDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data, self.transform = data, transform\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        image = cv2.cvtColor(cv2.imread(item['image_path']), cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        return image, torch.tensor(item['binary_labels'], dtype=torch.float32)\n",
        "\n",
        "# Аугментации - БАЛАНС КАЧЕСТВА И ПАМЯТИ\n",
        "IMG_SIZE = 512  # Баланс: не урезанный (как 224), но поместится в память\n",
        "train_tfm = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.8),\n",
        "    # Убираем проблемный GaussNoise - оставляем только Blur\n",
        "    A.Blur(blur_limit=3, p=0.3),\n",
        "    A.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "val_tfm = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "if not all_data:\n",
        "    print(\"Данные не загружены. Запустите предыдущие ячейки.\")\n",
        "else:\n",
        "    # Подготовка данных\n",
        "    train_data = [x for x in all_data if x['split'] in ['train']]\n",
        "    val_data = [x for x in all_data if x['split'] in ['valid', 'val', 'test']]\n",
        "    if not val_data:\n",
        "        train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "    vprint(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
        "\n",
        "    # Загрузчики данных - БАЛАНС ЭФФЕКТИВНОСТИ И ПАМЯТИ\n",
        "    batch_size = 12  # Баланс: больше 8, но меньше 16 для стабильности\n",
        "    train_loader = DataLoader(MultiLabelCarDataset(train_data, train_tfm), batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(MultiLabelCarDataset(val_data, val_tfm), batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    vprint(f\"Параметры: batch_size={batch_size}, {IMG_SIZE}x{IMG_SIZE} изображения, EfficientNetV2-S\")\n",
        "\n",
        "    # АГРЕССИВНАЯ ОЧИСТКА ПАМЯТИ\n",
        "    import gc\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()  # Ждем завершения всех операций\n",
        "        gc.collect()  # Принудительный сбор мусора Python\n",
        "        print(\"Очистка GPU кеша и GC выполнена\")\n",
        "        print(f\"💾 Свободно GPU памяти: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1024**3:.1f} GB\")\n",
        "\n",
        "    # Подсчет весов классов для балансировки (редкие классы получат больший вес)\n",
        "    labels_array = np.array([item['binary_labels'] for item in train_data])\n",
        "    class_counts = labels_array.sum(axis=0)\n",
        "    total_samples = len(train_data)\n",
        "\n",
        "    # Вычисляем веса: чем реже класс, тем больше вес\n",
        "    class_weights = []\n",
        "    for i, count in enumerate(class_counts):\n",
        "        if count > 0:\n",
        "            weight = total_samples / (len(BINARY_CLASSES) * count)\n",
        "            class_weights.append(weight)\n",
        "        else:\n",
        "            class_weights.append(1.0)\n",
        "\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "    print(f\"Веса классов: {dict(zip(BINARY_CLASSES, class_weights.cpu().numpy()))}\")\n",
        "\n",
        "    # МАКСИМАЛЬНАЯ ОЧИСТКА ПАМЯТИ ПЕРЕД СОЗДАНИЕМ МОДЕЛИ\n",
        "    import gc, os\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"Очистка памяти и антифрагментация выполнены\")\n",
        "\n",
        "    # Модель и оптимизация с взвешенными потерями\n",
        "    model = MultiLabelCarClassifier().to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)  # Взвешенные потери\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)  # Увеличили LR - отличные результаты позволяют\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=8)  # Оптимизировано для 40 эпох\n",
        "\n",
        "    print(\"Запуск обучения Multi-Label Binary Classification\")\n",
        "    print(\"   EfficientNetV2-S, 512x512, batch=12\")\n",
        "    print(\"   Ключ: больше чистых примеров из категории 'car' → правильная классификация чистых\")\n",
        "    print(\"   Баланс качества и стабильности памяти\")\n",
        "\n",
        "    # ОСНОВНОЙ ЦИКЛ ОБУЧЕНИЯ\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    best_f1, patience_counter = 0, 0\n",
        "\n",
        "    for epoch in range(40):  # Увеличили до 40 - отличные результаты и ресурсы позволяют!\n",
        "        # Обучение с градиентным накоплением\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        optimizer.zero_grad()  # Обнуляем градиенты в начале эпохи\n",
        "\n",
        "        for data, targets in tqdm(train_loader, desc=f'Эпоха {epoch+1}'):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Валидация\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for data, targets in val_loader:\n",
        "                outputs = model(data.to(device))\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                all_preds.append(preds.cpu().numpy())\n",
        "                all_targets.append(targets.numpy())\n",
        "\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_targets = np.concatenate(all_targets)\n",
        "\n",
        "        # Метрики\n",
        "        class_f1s = [f1_score(all_targets[:,i], all_preds[:,i], zero_division=0) for i in range(5)]\n",
        "        avg_f1 = np.mean(class_f1s)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Очистка памяти после каждой эпохи\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"Эпоха {epoch+1}: F1={avg_f1:.4f}, Clean F1={class_f1s[4]:.4f}\")\n",
        "        if epoch % 5 == 0:  # Показывать каждые 5 эпох для 40 эпох обучения\n",
        "            for cls, f1 in zip(BINARY_CLASSES, class_f1s):\n",
        "                print(f\"  {cls}: {f1:.3f}\")\n",
        "\n",
        "            # Показать использование GPU памяти\n",
        "            if torch.cuda.is_available():\n",
        "                memory_used = torch.cuda.memory_allocated() / 1024**3\n",
        "                print(f\"  GPU память: {memory_used:.1f}/15 GB\")\n",
        "\n",
        "        if avg_f1 > 0.68:\n",
        "            print(f\"Достигнута базовая линия {0.68}. F1={avg_f1:.4f}\")\n",
        "\n",
        "        # Сохранение лучшей модели\n",
        "        if avg_f1 > best_f1:\n",
        "            best_f1 = avg_f1\n",
        "            patience_counter = 0\n",
        "            torch.save({'model_state_dict': model.state_dict(), 'f1': best_f1, 'class_f1s': class_f1s}, 'best_model.pth')\n",
        "            print(f\"Сохранена лучшая модель. F1={best_f1:.4f}\")\n",
        "\n",
        "            # Проверка на решение проблемы ментора\n",
        "            if class_f1s[4] > 0.8:  # Clean F1 > 0.8\n",
        "                print(\"Критерий для clean выполнен (F1 > 0.8)\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= 10:  # Увеличили patience для 40 эпох\n",
        "                print(\"Ранняя остановка\")\n",
        "                break\n",
        "\n",
        "        # Очистка памяти в конце каждой эпохи\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Подсчет времени обучения\n",
        "    total_time = time.time() - start_time\n",
        "    hours = int(total_time // 3600)\n",
        "    minutes = int((total_time % 3600) // 60)\n",
        "\n",
        "    print(f\"\\nОбучение завершено (40 эпох, {hours}ч {minutes}мин)\")\n",
        "    print(f\"Итоговые результаты:\")\n",
        "    print(f\"   Лучший F1: {best_f1:.4f}\")\n",
        "    print(f\"   Цель F1 > 0.68: {'ДОСТИГНУТО' if best_f1 > 0.68 else 'НЕ ДОСТИГНУТО'}\")\n",
        "\n",
        "    if best_f1 > 0.68:\n",
        "        improvement = (best_f1 - 0.68) / 0.68 * 100\n",
        "        print(f\"Превышение базовой линии: +{improvement:.1f}%\")\n",
        "        print(f\"Подход с дополнительными clean-примерами подтвержден\")\n",
        "\n",
        "    # Показать финальные метрики по классам\n",
        "    checkpoint = torch.load('best_model.pth')\n",
        "    if 'class_f1s' in checkpoint:\n",
        "        final_f1s = checkpoint['class_f1s']\n",
        "        print(f\"\\nF1 по классам:\")\n",
        "        for cls, f1 in zip(BINARY_CLASSES, final_f1s):\n",
        "            print(f\"   {cls}: {f1:.3f}\")\n",
        "\n",
        "        if final_f1s[4] > 0.8:  # Clean F1\n",
        "            print(f\"\\nКритерий для clean выполнен: {final_f1s[4]:.3f} > 0.8\")\n",
        "\n",
        "    # Улучшенная функция тестирования\n",
        "    def test_prediction(image_path):\n",
        "        model.eval()\n",
        "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "        tensor = val_tfm(image=image)['image'].unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(model(tensor))[0].cpu().numpy()\n",
        "\n",
        "        print(\"Предсказания модели:\")\n",
        "        for cls, prob in zip(BINARY_CLASSES, probs):\n",
        "            print(f\"  {cls}: {prob:.3f}\")\n",
        "\n",
        "        # Определение основного состояния\n",
        "        max_idx = np.argmax(probs)\n",
        "        main_state = BINARY_CLASSES[max_idx]\n",
        "        confidence = probs[max_idx]\n",
        "        print(f\"\\nОсновное состояние: {main_state} ({confidence:.1%})\")\n",
        "        return probs\n",
        "\n",
        "    print(\"\\nФункция тестирования готова:\")\n",
        "    print(\"test_prediction('path_to_image.jpg') — для проверки на чистой машине\")\n",
        "    print(\"Ожидаемо: clean=0.9, scratch=0.05\")\n",
        "\n",
        "    # Финальная очистка памяти\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\nGPU память: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        print(f\"Используется: {torch.cuda.memory_allocated() / 1024**3:.1f} GB\")\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"Финальная очистка кеша выполнена\")\n",
        "\n",
        "        # ===== Интерактивное тестирование на своих фотографиях =====\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Интерактивное тестирование на ваших фотографиях\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Используйте ячейку 6 для загрузки и тестирования своих фотографий\")\n",
        "    print(\"Модель покажет: scratch, dent, rust, dirt, clean\")\n",
        "    print(\"Ожидаемо: чистые машины → clean > 0.8, поврежденные → соответствующие классы\")\n",
        "    print(\"\\nПосле завершения обучения запустите ячейку 6 для интерактивного тестирования\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9cK2Pjpp7N"
      },
      "source": [
        "## Интерактивное тестирование — отдельная ячейка\n",
        "\n",
        "Если обучение завершено, запустите только эту ячейку для тестирования на своих фотографиях.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8fMi-GGpp7N"
      },
      "outputs": [],
      "source": [
        "# ===== ОТДЕЛЬНОЕ ТЕСТИРОВАНИЕ НА ВАШИХ ФОТОГРАФИЯХ =====\n",
        "# Запустите эту ячейку если обучение уже завершено и модель сохранена\n",
        "\n",
        "# ===== ИМПОРТЫ (все необходимые библиотеки) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "# Устройство и базовые переменные\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BINARY_CLASSES = ['scratch', 'dent', 'rust', 'dirt', 'clean']\n",
        "\n",
        "# Трансформации для валидации (должны совпадать с обучением)\n",
        "val_tfm = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "print(\"Тестирование на ваших фотографиях\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Проверим, есть ли обученная модель\n",
        "import os\n",
        "if not os.path.exists('best_model.pth'):\n",
        "    print(\"Обученная модель не найдена\")\n",
        "    print(\"   Сначала запустите обучение (ячейка 5)\")\n",
        "else:\n",
        "    # Загрузим модель если её нет в памяти\n",
        "    try:\n",
        "        # Проверим, существует ли модель в памяти\n",
        "        model\n",
        "        print(\"Модель уже загружена в память\")\n",
        "    except NameError:\n",
        "        print(\"Загружаем обученную модель...\")\n",
        "\n",
        "        # Переопределяем класс модели (на случай перезапуска)\n",
        "        class MultiLabelCarClassifier(nn.Module):\n",
        "            def __init__(self, num_classes=5):\n",
        "                super().__init__()\n",
        "                self.backbone = timm.create_model('tf_efficientnetv2_s.in1k', pretrained=True, num_classes=0)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    dummy = torch.randn(1, 3, 512, 512)\n",
        "                    feat_dim = self.backbone(dummy).shape[1]\n",
        "\n",
        "                self.classifier = nn.Sequential(\n",
        "                    nn.Dropout(0.3), nn.Linear(feat_dim, 512), nn.ReLU(),\n",
        "                    nn.Dropout(0.2), nn.Linear(512, num_classes)\n",
        "                )\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.classifier(self.backbone(x))\n",
        "\n",
        "        # Загружаем модель\n",
        "        model = MultiLabelCarClassifier().to(device)\n",
        "        checkpoint = torch.load('best_model.pth')\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.eval()\n",
        "        print(f\"Модель загружена. F1 = {checkpoint['f1']:.4f}\")\n",
        "\n",
        "# Быстрая функция тестирования одного изображения\n",
        "def quick_test(image_path):\n",
        "    \"\"\"Быстрое тестирование одного изображения\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"❌ Не удалось загрузить {image_path}\")\n",
        "        return\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Предсказание\n",
        "    tensor = val_tfm(image=image_rgb)['image'].unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tensor)\n",
        "        probs = torch.sigmoid(outputs)[0].cpu().numpy()\n",
        "\n",
        "    # Результат\n",
        "    max_idx = np.argmax(probs)\n",
        "    main_pred = BINARY_CLASSES[max_idx]\n",
        "    confidence = probs[max_idx]\n",
        "\n",
        "    print(f\"Основное состояние: {main_pred.upper()} ({confidence:.1%})\")\n",
        "    for cls, prob in zip(BINARY_CLASSES, probs):\n",
        "        print(f\"   {cls}: {prob:.3f}\")\n",
        "\n",
        "    return probs\n",
        "\n",
        "# Загрузка и тестирование\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_multiple_images():\n",
        "    \"\"\"Загрузить и протестировать несколько изображений\"\"\"\n",
        "    print(\"Загрузите фотографии машин:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"Файлы не загружены\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            print(f\"\\nАнализируем: {filename}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            # Быстрый тест\n",
        "            probs = quick_test(filename)\n",
        "            if probs is not None:\n",
        "                results.append((filename, probs))\n",
        "\n",
        "            # Показать изображение\n",
        "            image = cv2.imread(filename)\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.title(filename)\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            colors = ['green' if p > 0.5 else 'orange' if p > 0.3 else 'lightblue'\n",
        "                     for p in probs]\n",
        "            bars = plt.bar(BINARY_CLASSES, probs, color=colors)\n",
        "            plt.title('Предсказания')\n",
        "            plt.ylabel('Вероятность')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            for bar, prob in zip(bars, probs):\n",
        "                plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
        "                        f'{prob:.2f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # Сводка результатов\n",
        "    if results:\n",
        "        print(f\"\\nСводка по {len(results)} изображениям:\")\n",
        "        for filename, probs in results:\n",
        "            main_idx = np.argmax(probs)\n",
        "            main_class = BINARY_CLASSES[main_idx]\n",
        "            confidence = probs[main_idx]\n",
        "            print(f\"   {filename}: {main_class.upper()} ({confidence:.1%})\")\n",
        "\n",
        "    print(\"\\nТестирование завершено\")\n",
        "\n",
        "# Создаем кнопки для удобства\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "print(\"\\nВыберите способ тестирования:\")\n",
        "\n",
        "# Кнопка для загрузки множества изображений\n",
        "multi_button = widgets.Button(\n",
        "    description=\"ЗАГРУЗИТЬ НЕСКОЛЬКО ФОТО\",\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='250px', height='40px')\n",
        ")\n",
        "\n",
        "def on_multi_clicked(b):\n",
        "    test_multiple_images()\n",
        "\n",
        "multi_button.on_click(on_multi_clicked)\n",
        "\n",
        "print(\"Кликните для загрузки и анализа ваших фотографий:\")\n",
        "display(multi_button)\n",
        "\n",
        "print(\"\\nАльтернативно, можно использовать функции напрямую:\")\n",
        "print(\"   • test_multiple_images() - для загрузки нескольких фото\")\n",
        "print(\"   • quick_test('filename.jpg') - для быстрого тестирования одного файла\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNfWuxiEpp7N"
      },
      "source": [
        "## Быстрая проверка готовности\n",
        "\n",
        "Запустите эту ячейку, чтобы проверить, что всё готово к работе.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Bh6Wsn-pp7O"
      },
      "outputs": [],
      "source": [
        "# БЫСТРАЯ ДИАГНОСТИКА ГОТОВНОСТИ К ОБУЧЕНИЮ/ТЕСТИРОВАНИЮ\n",
        "\n",
        "print(\"ПРОВЕРКА ГОТОВНОСТИ К РАБОТЕ\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Проверка библиотек\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import timm\n",
        "    import albumentations as A\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    print(\"Все библиотеки установлены\")\n",
        "except ImportError as e:\n",
        "    print(f\"Ошибка импорта: {e}\")\n",
        "    print(\"   Запустите ячейку 1 (Установка библиотек)\")\n",
        "\n",
        "# Проверка GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU доступен: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"   GPU память: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"GPU недоступен, будет использоваться CPU\")\n",
        "\n",
        "# Проверка данных\n",
        "if 'all_data' in globals() and all_data:\n",
        "    labels_array = np.array([item['binary_labels'] for item in all_data])\n",
        "    print(f\"Данные загружены: {len(all_data)} изображений\")\n",
        "    print(\"   Распределение классов:\")\n",
        "    BINARY_CLASSES = ['scratch', 'dent', 'rust', 'dirt', 'clean']\n",
        "    for i, cls in enumerate(BINARY_CLASSES):\n",
        "        count = labels_array[:, i].sum()\n",
        "        print(f\"      {cls}: {count} ({count/len(all_data)*100:.1f}%)\")\n",
        "else:\n",
        "    print(\"Данные не загружены\")\n",
        "    print(\"   Запустите ячейки по порядку: 2 → 3 → 4\")\n",
        "\n",
        "# Проверка модели\n",
        "if os.path.exists('best_model.pth'):\n",
        "    checkpoint = torch.load('best_model.pth', map_location='cpu')\n",
        "    print(f\"Обученная модель найдена\")\n",
        "    print(f\"   F1 Score: {checkpoint.get('f1', 'N/A')}\")\n",
        "    if 'class_f1s' in checkpoint:\n",
        "        print(\"   F1 по классам:\")\n",
        "        for cls, f1 in zip(BINARY_CLASSES, checkpoint['class_f1s']):\n",
        "            print(f\"      {cls}: {f1:.3f}\")\n",
        "else:\n",
        "    print(\"Обученная модель не найдена\")\n",
        "    print(\"   Нужно запустить обучение (ячейка 5)\")\n",
        "\n",
        "print(\"\\nСледующие шаги:\")\n",
        "if 'all_data' not in globals() or not all_data:\n",
        "    print(\"   1. Запустите ячейки 2-4 для загрузки данных\")\n",
        "    print(\"   2. Затем запустите ячейку 5 для обучения\")\n",
        "    print(\"   3. После обучения используйте ячейку 6 для тестирования\")\n",
        "elif not os.path.exists('best_model.pth'):\n",
        "    print(\"   1. Запустите ячейку 5 для обучения модели\")\n",
        "    print(\"   2. После обучения используйте ячейку 6 для тестирования\")\n",
        "else:\n",
        "    print(\"   Все готово. Можно:\")\n",
        "    print(\"      - Дообучить модель (ячейка 5)\")\n",
        "    print(\"      - Тестировать свои фото (ячейка 6)\")\n",
        "\n",
        "print(f\"\\nТекущее состояние:\")\n",
        "print(f\"   Устройство: {device}\")\n",
        "print(f\"   Данные: {'Загружены' if 'all_data' in globals() and all_data else 'Не загружены'}\")\n",
        "print(f\"   Модель: {'Обучена' if os.path.exists('best_model.pth') else 'Не обучена'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQYTQC2kpp7O"
      },
      "source": [
        "## Итоги\n",
        "\n",
        "### Что сделано\n",
        "\n",
        "1. Определена корневая причина: недостаток чистых машин в обучении.\n",
        "2. Решение: категория \"car\" интерпретируется как метка \"clean\".\n",
        "3. Мульти‑лейбл бинарная классификация: 5 независимых меток.\n",
        "4. Balanced аугментации и корректная выборка улучшили устойчивость к реальным фото.\n",
        "5. BCEWithLogitsLoss с весами классов для дисбаланса.\n",
        "\n",
        "Итоговые метрики (макро F1): 0.8352\n",
        "\n",
        "- scratch: 0.750\n",
        "- dent:   0.714\n",
        "- rust:   0.889\n",
        "- dirt:   0.944\n",
        "- clean:  0.879\n",
        "\n",
        "### Как протестировать\n",
        "\n",
        "```python\n",
        "# После обучения:\n",
        "probs = test_prediction(\"path/to/clean_car.jpg\")\n",
        "# Ожидаемо: clean > 0.8, scratch < 0.1\n",
        "```\n",
        "\n",
        "### Вывод\n",
        "\n",
        "- Не требуется сложный многоэтапный пайплайн.\n",
        "- Нужны корректные данные с достаточным числом чистых примеров.\n",
        "- Мульти‑лейбл бинарный подход корректно решает задачу."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c8488c25d848b3bb293633293d0460": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e10b07105194f6c8e4c664a0f6f5746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e84c4581b64438b8230db7ada722d73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447ba533d0ea4df1b4172773b318297b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfadec0698b741ca9c79ca041c6dea4a",
            "placeholder": "​",
            "style": "IPY_MODEL_5e58631bd178407f981b41d03219d732",
            "value": "model.safetensors: 100%"
          }
        },
        "5e58631bd178407f981b41d03219d732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a18b990ecd492b8103ef510a42f0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_447ba533d0ea4df1b4172773b318297b",
              "IPY_MODEL_f38be968b2f947d094e1d30b19797f46",
              "IPY_MODEL_d960fcbd3e334d9dad2ff80e60834645"
            ],
            "layout": "IPY_MODEL_7bb399cb03cb45ad83cc5a441039eb45"
          }
        },
        "7bb399cb03cb45ad83cc5a441039eb45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938cb74eebdb4793905cb5313b81d3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d960fcbd3e334d9dad2ff80e60834645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e84c4581b64438b8230db7ada722d73",
            "placeholder": "​",
            "style": "IPY_MODEL_0e10b07105194f6c8e4c664a0f6f5746",
            "value": " 86.5M/86.5M [00:00&lt;00:00, 140MB/s]"
          }
        },
        "dfadec0698b741ca9c79ca041c6dea4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38be968b2f947d094e1d30b19797f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938cb74eebdb4793905cb5313b81d3a7",
            "max": 86523256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00c8488c25d848b3bb293633293d0460",
            "value": 86523256
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
